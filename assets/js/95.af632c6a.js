(window.webpackJsonp=window.webpackJsonp||[]).push([[95],{506:function(_,v,a){"use strict";a.r(v);var i=a(6),l=Object(i.a)({},(function(){var _=this,v=_._self._c;return v("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[v("p",[_._v("负责人：杨小龙，梁汝通，参与人：梁汝通")]),_._v(" "),v("h2",{attrs:{id:"_2023-08-28-2023-09-01"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_2023-08-28-2023-09-01"}},[_._v("#")]),_._v(" 2023.08.28 - 2023.09.01")]),_._v(" "),v("details",[v("summary",[_._v("完成数据湖仓一体化服务器端Hadoop,Spark,Mysql,Kafka,Maven,Scala,Zookeeper,Jdk的环境部署")]),_._v(" "),v("ul",[v("li",[_._v("1.完成mysql数据库安装:目的需要监测binlog数据同步至kafka")]),_._v(" "),v("li",[_._v("2.完成hive的安装:配置完成与hadoop的集成")]),_._v(" "),v("li",[_._v("3.完成zookeeper协调分布式服务安装")]),_._v(" "),v("li",[_._v("4.完成kafka的服务安装,并完成集成zookeeper")])])]),_._v(" "),v("hr"),_._v(" "),v("p",[_._v("负责人：杨小龙，梁汝通，参与人：梁汝通")]),_._v(" "),v("h2",{attrs:{id:"_2023-09-04-2023-09-08"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_2023-09-04-2023-09-08"}},[_._v("#")]),_._v(" 2023.09.04 - 2023.09.08")]),_._v(" "),v("details",[v("summary",[_._v("以官方提供的数据在IDEA开发环境进行业务开发")]),_._v(" "),v("ul",[v("li",[_._v("1.订单类型统计")]),_._v(" "),v("li",[_._v("2.订单时效性统计")]),_._v(" "),v("li",[_._v("3.订单交通类型统计")]),_._v(" "),v("li",[_._v("4.订单价格区间统计")]),_._v(" "),v("li",[_._v("5.订单举例统计")]),_._v(" "),v("li",[_._v("6.订单星期统计")])])]),_._v(" "),v("details",[v("summary",[_._v("集成以安装部署的hive服务完成以下功能")]),_._v(" "),v("ul",[v("li",[_._v("1.创建表和添加分区")]),_._v(" "),v("li",[_._v("2.集成Hive查询,通过Hive SQL实现指标分析")]),_._v(" "),v("li",[_._v("3.模拟交易订单数据和流程分析")]),_._v(" "),v("li",[_._v("4.结构化流写入Hudi")]),_._v(" "),v("li",[_._v("5.结构化流式数据查询分析")]),_._v(" "),v("li",[_._v("6.DeltaStreamer工具使用")])])]),_._v(" "),v("hr"),_._v(" "),v("p",[_._v("负责人：杨小龙，梁汝通，参与人：梁汝通")]),_._v(" "),v("h2",{attrs:{id:"_2023-09-01-2023-09-12"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_2023-09-01-2023-09-12"}},[_._v("#")]),_._v(" 2023.09.01 - 2023.09.12")]),_._v(" "),v("details",[v("summary",[_._v("流式数据入湖")]),_._v(" "),v("ul",[v("li",[_._v("1.模拟产生订单数据")]),_._v(" "),v("li",[_._v("2.集成kafka并完成数据写入")]),_._v(" "),v("li",[_._v("3.消费kafka数据流式加载")]),_._v(" "),v("li",[_._v("4.kafka数据InputDStream[ConsumerRecord[String,String]]结构化数据处理")]),_._v(" "),v("li",[_._v('5.使用scala语言的"柯里化"（Currying)技术完成批量数据实时处理')]),_._v(" "),v("li",[_._v("6.将DStream RDD数据转换为DataFrame结构,并写入Hudi")])])]),_._v(" "),v("details",[v("summary",[_._v("定西项目应用")]),_._v(" "),v("ul",[v("li",[_._v("1.完成居民数据的导入")]),_._v(" "),v("li",[_._v("2.从Hudi中加载数据按需展示在后台系统中")]),_._v(" "),v("li",[_._v("3.对人员数据使用spark实现统计功能")])])])])}),[],!1,null,null,null);v.default=l.exports}}]);